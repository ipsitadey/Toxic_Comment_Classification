# Toxic_Comment_Classification

Social media and online portals are becoming raging platforms for expressing hatred and biases towards certain communities. **Cyber Bullying** has become a serious worldwide issue and needs to be countered. Our goal is to identify such hateful and abusive content with high accuracy so that one could safely use these platforms to express their opinion without being disrespectful. To address these needs, in this study we investigate the ability of **BERT(Bidirectional Encoder Representations from Transformers)**, a pre-trained state-of the art NLP model, at capturing hateful context within social media content by using new finetuning methods based on transfer learning.

## What is BERT?
* General purpose Bidirectional Contextual language model
* A Transformer Encoder stack trained on Wikipedia and Book Corpus
* Performs better than deep learning models when finetuned for classification task

Novel processing ideas of BERT
Way to “fill in the blank” based on context. e.g: *“She bought a _____ of shoes.”* pair 80% 
